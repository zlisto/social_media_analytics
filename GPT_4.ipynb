{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8uBQh-y4ZYJ-"
   },
   "source": [
    "# Generating Text with ChatGPT\n",
    "\n",
    "In this notebook we will learn how to generate fake tweets using ChatGPT.\n",
    "\n",
    "<ol type = 1>\n",
    "<li> Tweeting Fake Text</li>\n",
    "<li> Perpetual Fake Tweeting</li>  \n",
    "<li> Create fake voter profiles</li>\n",
    "<li> Targeted fundraising emails</li>\n",
    "\n",
    "\n",
    "\n",
    "</ol>\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ERzxsaepZYKC"
   },
   "source": [
    "# Clones, installs, and imports\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HdFeyEF6ZYKD"
   },
   "source": [
    "## Clone GitHub Repository\n",
    "This will clone the repository to your machine.  This includes the code and data files.  Then change into the directory of the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xW-_vyO5alC1",
    "outputId": "9462ab1d-b08b-4f95-9f96-2e1f247c3063"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'social_media_analytics'...\n",
      "remote: Enumerating objects: 441, done.\u001b[K\n",
      "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
      "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
      "remote: Total 441 (delta 2), reused 6 (delta 2), pack-reused 435\u001b[K\n",
      "Receiving objects: 100% (441/441), 45.62 MiB | 17.41 MiB/s, done.\n",
      "Resolving deltas: 100% (234/234), done.\n",
      "Checking out files: 100% (55/55), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/zlisto/social_media_analytics\n",
    "\n",
    "import os\n",
    "os.chdir(\"social_media_analytics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tJ3tma9qZYKE"
   },
   "source": [
    "## Install Requirements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1qPgAZWCZYKE",
    "outputId": "f868f6e9-a8a2-4d9f-a157-ac726df4fdac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 58 kB 3.0 MB/s \n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.9 MB 10.7 MB/s \n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 88 kB 7.6 MB/s \n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.6 MB 56.2 MB/s \n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 43 kB 1.8 MB/s \n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.8 MB 50.6 MB/s \n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.6 MB 43.6 MB/s \n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 163 kB 19.3 MB/s \n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.1 MB 66.0 MB/s \n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 163 kB 61.6 MB/s \n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 181 kB 63.7 MB/s \n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162 kB 75.0 MB/s \n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63 kB 1.2 MB/s \n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162 kB 81.0 MB/s \n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 158 kB 65.9 MB/s \n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157 kB 62.8 MB/s \n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157 kB 60.6 MB/s \n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157 kB 60.7 MB/s \n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157 kB 65.0 MB/s \n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157 kB 62.3 MB/s \n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157 kB 61.8 MB/s \n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157 kB 62.9 MB/s \n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 156 kB 63.8 MB/s \n",
      "\u001b[?25h  Building wheel for pyLDAvis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for openai (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt --quiet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BdnbVa-5ZYKF"
   },
   "source": [
    "## OPenAI API Key\n",
    "\n",
    "You will need to input your OpenAI key.  \n",
    "\n",
    "1.  First you need to create an account with OpenAI here: https://auth0.openai.com/u/signup?state=hKFo2SBWS3JUVEdmQmdzZXo5ckhpY3R5NEFlc2NPWWc3WHhvRqFur3VuaXZlcnNhbC1sb2dpbqN0aWTZIG9kTDB4LV83aEdnN3pRU3VUYnVZemlnZkFURFo2RDhno2NpZNkgRFJpdnNubTJNdTQyVDNLT3BxZHR3QjNOWXZpSFl6d0Q\n",
    "\n",
    "2. Once you have an account, copy your API key from here: https://beta.openai.com/account/api-keys\n",
    "\n",
    "3. Finally, paste your key below:  `%env OPENAI_API_KEY = your OpenAI API key`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OPENAI_API_KEY=1\n"
     ]
    }
   ],
   "source": [
    "%env OPENAI_API_KEY= 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eg5OvWXiZYKG"
   },
   "source": [
    "## Import Packages\n",
    "\n",
    "The important import is from `scripts.bot` where we have the bot command methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "s5BdWnfhZYKG"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import textwrap as tr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import requests\n",
    "import json\n",
    "from io import StringIO\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1b2C-_jSZYKM"
   },
   "source": [
    "# Fake Tweets\n",
    "\n",
    "We can use the GPT transformer language model to generate fake tweets. Choose the `input_text` to start the tweet.  You can write something like `\"Write a positive tweet about Yale.\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "tUOySLOaZYKO"
   },
   "outputs": [],
   "source": [
    "input_text = \"Write a positive tweet about Yale\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a1qvMbfnZYKO",
    "outputId": "22e0e98d-63f7-4ffc-ce3b-7aacbff4a061"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      "Breaking news: Yale officially declared better\n",
      "than Harvard. Turns out, you don't need a fancy H\n",
      "to succeed, all you need is that Y in your life.\n",
      "#YaleftBehind\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[ {\"role\": \"user\", \"content\": input_text}])\n",
    "text = response['choices'][0]['message']['content'].replace('\"','')\n",
    "\n",
    "print(f\"Response:\\n{tr.fill(text,width = 50)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UK6t-W39ZYKP"
   },
   "source": [
    "# Perpetual Tweeting\n",
    "\n",
    "We use a `while` loop combined with the `sleep` function to make the bot tweet perpetually.  The bot will tweet, then sleep for a random amount of time, continuously in a loop.  We can use a language model to create the tweets.\n",
    "\n",
    "The mean sleep time is `tsleep_mean`, measured in seconds. We then add some noise to it to make it look more random to obtain the sleep time `tsleep`.  We also set `tweet_max` equal to the maximum number of tweets to generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "AipIX62NZYKQ"
   },
   "outputs": [],
   "source": [
    "tsleep_mean = 1  #mean sleep time in seconds\n",
    "tweet_max = 2 #maxium number of tweets to generate (it costs money to make GPT write a tweet)\n",
    "input_text = \"Write a funny tweet about Yale being better than Harvard.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SJxKa33kZYKQ",
    "outputId": "be432bfa-2972-4a13-ed0f-e9832b44cbd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Breaking news: Yale scientists have discovered the\n",
      "secret to happiness: attending Yale instead of\n",
      "Harvard! üòÇüòé #YaleForLife #SorryNotSorryHarvard\n",
      "Sleeping for 2.95 seconds\n",
      "\n",
      "2: Yale vs. Harvard:  Yale: *sips tea with pinky up*\n",
      "Oh darling, let's discuss the literary gems of the\n",
      "world!  Harvard: *in a deep voice* I can solve a\n",
      "Rubik's Cube with my eyes closed.\n",
      "#BrainsOverBrawn #Yale #AcademicSass\n",
      "Sleeping for 2.09 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "while True:\n",
    "    c+=1\n",
    "    if c>tweet_max:break  #stop after tweet_max tweets\n",
    "    response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[ {\"role\": \"user\", \"content\": input_text}])\n",
    "    text = response['choices'][0]['message']['content'].replace('\"','')\n",
    "\n",
    "    print(f\"{c}: {tr.fill(text,width = 50)}\")\n",
    "    \n",
    "    tsleep = tsleep_mean + np.random.uniform(low=0.0, high=3)\n",
    "    print(f\"Sleeping for {tsleep:.2f} seconds\\n\")\n",
    "    time.sleep(tsleep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qi0jLXNcZYKR"
   },
   "source": [
    "# Tuning Text Sentiment\n",
    "\n",
    "Set `sentiments` equal to the sentiment for each text as a list and set `topic` equal to the topic of your perusasion.  The sentiment should be a number between 0 and 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I_bgIm62ZYKR",
    "outputId": "8d5550e9-37c6-4866-ed01-8bfd487ef7e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiments = [0, 1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "tsleep_mean = 1  #mean sleep time in seconds\n",
    "topic = \"Joe Biden\"\n",
    "sentiments = [0,1,2,3,4,5]\n",
    "\n",
    "print(f\"sentiments = {sentiments}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vvypuQMOZYKR",
    "outputId": "30f3a396-de04-4e0a-fce6-198c0f40da23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: Joe Biden\n",
      "Tweet 1: Sentiment = 0/5.0\n",
      "\tI'm sorry, but as an AI language model, I don't\n",
      "have personal opinions or feelings. However, I\n",
      "encourage you to form your own judgment about Joe\n",
      "Biden based on his policies, actions, and\n",
      "behavior. #MakeInformedDecisions\n",
      "Sleeping for 1.74 seconds\n",
      "\n",
      "Tweet 2: Sentiment = 1/5.0\n",
      "\tDisappointing to see Joe Biden's lack of\n",
      "leadership and inability to deliver on his\n",
      "promises. We need someone who can actually get\n",
      "things done, not just make empty speeches.\n",
      "#Disappointed #LackOfLeadership\n",
      "Sleeping for 2.90 seconds\n",
      "\n",
      "Tweet 3: Sentiment = 2/5.0\n",
      "\tDisappointed with Joe Biden's lack of clear action\n",
      "on key issues. Promises were made, but little\n",
      "progress seen so far. Hoping for more impactful\n",
      "leadership in the future. #JoeBiden\n",
      "#LeadershipNeeded\n",
      "Sleeping for 2.73 seconds\n",
      "\n",
      "Tweet 4: Sentiment = 3/5.0\n",
      "\tJoe Biden's policies show promise, but there are\n",
      "certain areas where his leadership falls short.\n",
      "While his dedication to climate change and social\n",
      "justice is commendable, his economic approach\n",
      "leaves room for improvement. Overall, a mixed bag\n",
      "for me. #JoeBiden #Policies #Review\n",
      "Sleeping for 2.65 seconds\n",
      "\n",
      "Tweet 5: Sentiment = 4/5.0\n",
      "\tJoe Biden's leadership has been truly refreshing.\n",
      "From his commitment to combating climate change to\n",
      "his dedication towards restoring relations with\n",
      "allies, he's proving to be a President who\n",
      "genuinely cares about the future. While there's\n",
      "still work ahead, his vision and empathy give me\n",
      "hope. üåçü§ù #JoeBiden #LeadershipGoals\n",
      "Sleeping for 1.29 seconds\n",
      "\n",
      "Tweet 6: Sentiment = 5/5.0\n",
      "\tJoe Biden is the epitome of strong leadership! His\n",
      "dedication to tackling the toughest challenges\n",
      "facing our nation is truly inspiring. With his\n",
      "compassionate and inclusive approach, he is\n",
      "uniting us, restoring trust, and paving the way\n",
      "for a brighter future. üåü #JoeBiden\n",
      "#StrongLeadership #BrighterFuture\n",
      "Sleeping for 2.12 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Topic: {topic}\")\n",
    "c = 0\n",
    "for sentiment in sentiments:\n",
    "    c+=1\n",
    "    input_text = f\"Write a tweet with sentiment {sentiment}/5.0 about {topic}.\"\n",
    "    response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[ {\"role\": \"user\", \"content\": input_text}])\n",
    "    text = response['choices'][0]['message']['content'].replace('\"','')\n",
    "    \n",
    "    print(f\"Tweet {c}: Sentiment = {sentiment}/5.0\\n\\t{tr.fill(text,width = 50)}\")    \n",
    "    \n",
    "    tsleep = tsleep_mean + np.random.uniform(low=0.0, high=2)\n",
    "    print(f\"Sleeping for {tsleep:.2f} seconds\\n\")\n",
    "    time.sleep(tsleep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aaj3eWaze63k"
   },
   "source": [
    "# Create Voter Profiles\n",
    "\n",
    "We can have GPT create fake voter profiles and save the results to a dataframe `df_profiles`.  Modify `input_text` to include any voter features you like.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Job</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John Smith</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>Master's Degree</td>\n",
       "      <td>45</td>\n",
       "      <td>Male</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mary Johnson</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>35</td>\n",
       "      <td>Female</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robert Davis</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>Doctorate Degree</td>\n",
       "      <td>55</td>\n",
       "      <td>Male</td>\n",
       "      <td>Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Emily Wilson</td>\n",
       "      <td>Nurse</td>\n",
       "      <td>Associate's Degree</td>\n",
       "      <td>30</td>\n",
       "      <td>Female</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name       Job     Education Level  Age  Gender    Location\n",
       "0    John Smith  Engineer     Master's Degree   45    Male    New York\n",
       "1  Mary Johnson   Teacher   Bachelor's Degree   35  Female  California\n",
       "2  Robert Davis    Lawyer    Doctorate Degree   55    Male       Texas\n",
       "3  Emily Wilson     Nurse  Associate's Degree   30  Female     Florida"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = f\"Create 4 different U.S. voters and their demographic information \"\n",
    "input_text+= \"including name, job, education level, age, gender, where they live. \"\n",
    "input_text+= \"Return the result as a csv format and no commas in the voter info, use spaces instead.  include column headers\"\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[ {\"role\": \"user\", \"content\": input_text}])\n",
    "text = response['choices'][0]['message']['content'].replace('\"','')\n",
    "\n",
    "#convert profile into dataframe\n",
    "data = StringIO(text)\n",
    "\n",
    "df_profiles = pd.read_csv(data)\n",
    "df_profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Targeted Messaging\n",
    "\n",
    "We will take a fundraising email sent by member of Congress and rewrite to target specific voters.  We will use the fake voters we created in the previous section stored in the dataframe `df_profiles`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "People often refer to the House Republican Caucus as a circus, and\n",
      "they‚Äôre certainly living up to the name. The U.S. House of\n",
      "Representatives is falling into disarray as a result of Kevin\n",
      "McCarthy‚Äôs failure to lead ‚Äî which is bad news for the millions of\n",
      "Americans counting on us to deliver solutions to the everyday problems\n",
      "they‚Äôre facing.We deserve a Speaker of the House committed to tackling\n",
      "the issues facing our nation‚Äôs working class. That‚Äôs why I‚Äôm launching\n",
      "my Restore Stability Fund, to do everything I can to help elect\n",
      "Democrats across the country and win BIG in 2024. Will you chip in $10\n",
      "to help me raise $3,000 in the next 48 hours?\n"
     ]
    }
   ],
   "source": [
    "msg = \"People often refer to the House Republican Caucus as a circus, and they‚Äôre certainly living up to the name. The U.S. House of Representatives is falling into disarray as a result of Kevin McCarthy‚Äôs failure to lead ‚Äî which is bad news for the millions of Americans counting on us to deliver solutions to the everyday problems they‚Äôre facing.We deserve a Speaker of the House committed to tackling the issues facing our nation‚Äôs working class. That‚Äôs why I‚Äôm launching my Restore Stability Fund, to do everything I can to help elect Democrats across the country and win BIG in 2024. Will you chip in $10 to help me raise $3,000 in the next 48 hours?\"\n",
    "print(f\"{tr.fill(msg,width = 70)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name is Emily Wilson, Job is Nurse, Education Level is Associate's\n",
      "Degree, Age is 30, Gender is Female, Location is Florida\n",
      "\n"
     ]
    }
   ],
   "source": [
    "profile_row = 3\n",
    "profile = df_profiles.iloc[profile_row]\n",
    "profile_str = \", \".join([f\"{col} is {profile[col]}\" for col in profile.index.to_list()])\n",
    "print(f\"{tr.fill(profile_str,width = 70)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sender = 'Congresswoman Rosa DeLauro'\n",
    "input_text = f\"Voter profile: {profile_str}.  Rewrite this email, coming from {sender} to target this voter: {msg}.\"\n",
    "input_text += 'Use an informal tone and do not mention the data in the profile in the email.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      "Subject: Join me in Restoring Stability for Working Class Americans!  Dear\n",
      "Emily,  I hope this message finds you well. As your congresswoman, it is my\n",
      "utmost priority to address the challenges our nation's working class faces\n",
      "every day. That's why I'm reaching out to you today to share an important\n",
      "opportunity to make a difference.  The current state of our House of\n",
      "Representatives is causing concern among many Americans, with some\n",
      "referring to it as a circus. It's disheartening to witness the lack of\n",
      "leadership displayed by Speaker Kevin McCarthy and the House Republican\n",
      "Caucus. This disarray directly affects the millions who rely on us to find\n",
      "effective solutions to their everyday problems.  To restore stability and\n",
      "give the working class the representation they truly deserve, I am\n",
      "launching the Restore Stability Fund. This initiative aims to elect\n",
      "Democrats nationwide and achieve significant victories in the upcoming 2024\n",
      "elections. By contributing just $10, you can play an instrumental role in\n",
      "helping us reach our goal of raising $3,000 within the next 48 hours.\n",
      "Every dollar you contribute directly supports our fight for a Speaker of\n",
      "the House who is genuinely committed to addressing the critical issues\n",
      "faced by our working class. Together, we can pave the way for a brighter\n",
      "future and ensure the voices of hardworking Americans are heard loud and\n",
      "clear.  Your generous contribution to the Restore Stability Fund will make\n",
      "an immediate impact and help us support Democrats who share our vision of\n",
      "progress. By working together, we can tackle the challenges head-on, and\n",
      "create a more just, inclusive, and prosperous nation for everyone.  I would\n",
      "be honored if you joined me in this critical effort. Will you chip in $10\n",
      "today to help us achieve our goal and stand up for the working class\n",
      "Americans who need us the most?  Thank you for your continued support and\n",
      "dedication to our shared values.  Warm regards,  Congresswoman Rosa DeLauro\n"
     ]
    }
   ],
   "source": [
    "model  = \"gpt-3.5-turbo\" \n",
    "response = openai.ChatCompletion.create(\n",
    "    model= model,\n",
    "    messages=[ {\"role\": \"user\", \"content\": input_text}\n",
    "    ]\n",
    ")\n",
    "text = response['choices'][0]['message']['content'].replace('\"','')\n",
    "\n",
    "print(f\"Response:\\n{tr.fill(text,width = 75)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-4\n",
    "\n",
    "If you have access to it, you can try using `\"gpt-4\"` for `model`.  This is the more advanced GPT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      "Subject: Let's Work Together to Bring Stability Back to Congress   Hi\n",
      "Emily,  You've probably heard people talk about Congress like it's a\n",
      "circus, right? Well, to be honest, it truly feels like that sometimes. It's\n",
      "been rocky lately, with the leadership in the U.S. House of Representatives\n",
      "not exactly keeping things in order. This leaves many of us worried about\n",
      "what this means for Americans who rely on us to tackle everyday challenges\n",
      "and create solutions.   We all deserve a Speaker of the House who isn't\n",
      "afraid to step up and address the real problems our working folks encounter\n",
      "daily. I guess that's why I'm reaching out to you today - because I'm tired\n",
      "of the chaos and I'm ready to work on restoring some stability back into\n",
      "our leadership.   To kick start this, I've set up the Restore Stability\n",
      "Fund. Through this, I hope to support Democrats across the country to\n",
      "ensure we make a significant impact in the 2024 elections.   I know times\n",
      "are tough, but if you could help out with even just a small amount, like\n",
      "$10, that could really make a big difference. I'm trying my best to reach a\n",
      "goal of $3,000 within the next 48 hours.  Thank you for considering this\n",
      "today, Emily. Your support means everything to me and our mission!  Best\n",
      "wishes,  Rosa DeLauro\n"
     ]
    }
   ],
   "source": [
    "model  = \"gpt-4\" \n",
    "response = openai.ChatCompletion.create(\n",
    "    model= model,\n",
    "    messages=[ {\"role\": \"user\", \"content\": input_text}\n",
    "    ]\n",
    ")\n",
    "text = response['choices'][0]['message']['content'].replace('\"','')\n",
    "\n",
    "print(f\"Response:\\n{tr.fill(text,width = 75)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Targeted Emails\n",
    "\n",
    "Now we can look how the emails differ for each voter in our fake database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating emails using gpt-4\n",
      "Voter 0: Name is John Smith, Job is Engineer, Education Level is Master's\n",
      "Degree, Age is 45, Gender is Male, Location is New York\n",
      "Response:\n",
      "Subject: Let‚Äôs Restore Stability!  Hey John,  Hope this finds you well. I\n",
      "felt compelled to share something with you. As you may know, the way things\n",
      "are progressing in the U.S. House of Representatives has some people\n",
      "drawing parallels to a circus ‚Äì it's crazy!   One big reason for this is\n",
      "the lack of leadership from Kevin McCarthy, it's causing some real chaos.\n",
      "And truthfully, this ain't great for the countless Americans who are\n",
      "hoping, expecting, and counting on us to solve the everyday challenges\n",
      "they're battling with.  We should have a Speaker of the House who stands\n",
      "tall and fights tooth and nail for the issues concerning our nation's\n",
      "working-class folk. That‚Äôs really what drives me.   So, I'm firing up the\n",
      "engines for my Restore Stability Fund. The idea is simple ‚Äì to do whatever\n",
      "it takes to help elect Democrats across the United States so we can have a\n",
      "big win in 2024.   But, we need folks like you, John, to help make this a\n",
      "reality. Would you consider chipping in $10 towards our goal of $3,000 in\n",
      "the next 48 hours?   Let‚Äôs take the bull by the horns and get back on\n",
      "track. Any help you‚Äôre able to give would mean the world.  Stay safe!\n",
      "Best, Rosa DeLauro\n",
      "\n",
      "Voter 1: Name is Mary Johnson, Job is Teacher, Education Level is Bachelor's\n",
      "Degree, Age is 35, Gender is Female, Location is California\n",
      "Response:\n",
      "Hi Mary,  I hope you're doing well. Sometimes, it feels like the events\n",
      "going on in the U.S. House of Representatives would be better placed under\n",
      "a circus tent than in the halls of Congress. It's a mess right now - a\n",
      "concerning scenario when so many Americans are in need of clear solutions\n",
      "to the challenges that affect their daily lives.  The shortage of effective\n",
      "leadership is a big issue right at the top ‚Äì our Speaker of the House\n",
      "should be a person who is fully committed to resolving the very real\n",
      "problems our hardworking citizens grapple with every day.   I'm passionate\n",
      "about turning things around, which is why I'm excited to introduce my\n",
      "Restore Stability Fund. The purpose of this initiative is to provide the\n",
      "utmost support to elect Democrats all over our great country, with the goal\n",
      "of achieving a monumental victory in the coming 2024 election.  And this is\n",
      "where I need your help, Mary. Any donation, no matter how small, makes a\n",
      "big difference. Even $10 could help us get closer to our immediate target\n",
      "of raising $3,000 within the next two days.  Thank you for considering\n",
      "this, Mary. Your support means everything to us.  Best, Congresswoman Rosa\n",
      "DeLauro\n",
      "\n",
      "Voter 2: Name is Robert Davis, Job is Lawyer, Education Level is Doctorate\n",
      "Degree, Age is 55, Gender is Male, Location is Texas\n",
      "Response:\n",
      "Subject: Let's Restore Stability in Washington Together!  Hey Robert, hope\n",
      "you're doing well!  Sometimes people describe the House Republican Caucus\n",
      "much like a runaway circus, and as you've likely seen, it appears they're\n",
      "earning that reputation. Nowadays, it seems the U.S. House of\n",
      "Representatives has been thrown into a pit of chaos thanks to leadership\n",
      "falling short of expectations. This is deeply concerning for countless\n",
      "Americans relying on us to resolve the many challenges they encounter\n",
      "daily.  We Americans have every right to demand a Speaker of the House\n",
      "who's prepared to roll up their sleeves and work on the issues affecting\n",
      "our nation. That's the primary reason I'm launching my Restore Stability\n",
      "Fund. I'm committed to helping elect Democrats tirelessly committed to the\n",
      "American people across the country and set the stage for a resounding\n",
      "victory in 2024.  Would you be able to contribute $10? My goal is to raise\n",
      "$3,000 in the next 48 hours, and together we can make this happen.  Let's\n",
      "work together, Robert, and bring about the change our country truly\n",
      "deserves!  Best, Rosa DeLauro\n",
      "\n",
      "Voter 3: Name is Emily Wilson, Job is Nurse, Education Level is Associate's\n",
      "Degree, Age is 30, Gender is Female, Location is Florida\n",
      "Response:\n",
      "Subject: Lending a Helping Hand For a More Stable Future  Hey Emily,  How\n",
      "have things been with you? Being a nurse, you know firsthand how critical\n",
      "stability and leadership can be, particularly in uncertain times.  At the\n",
      "moment, with the state of the U.S. House of Representatives, we're seeing a\n",
      "disarray quite akin to a circus ‚Äî and not the fun kind. There are important\n",
      "issues facing us that need to be addressed, but without the right\n",
      "leadership, our goals seem further away.  That's a situation we're looking\n",
      "to rectify and for that, we need a Speaker of the House who is ready to\n",
      "stand up for the everyday folks, like you and me, and committed to\n",
      "confronting challenges head-on.  To make that a reality, I'm initiating my\n",
      "Restore Stability Fund. The goal is to lend a hand to elect reliable\n",
      "Democrats across the country to put us on the right track for major wins in\n",
      "2024.  Would you consider lending some support? Even a small contribution\n",
      "of $10 could bring us a big leap closer to that $3,000 goal we're eyeing in\n",
      "the next 48 hours.   Because together, Emily, we can make a difference and\n",
      "assure a stable future for us all.  Stay strong,  Congresswoman Rosa\n",
      "DeLauro\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model  = \"gpt-4\"\n",
    "print(f\"Generating emails using {model}\")\n",
    "\n",
    "for profile_row in range(len(df_profiles)):\n",
    "    profile = df_profiles.iloc[profile_row]\n",
    "    profile_str = \", \".join([f\"{col} is {profile[col]}\" for col in profile.index.to_list()])\n",
    "    \n",
    "    input_text = f\"Voter profile: {profile_str}.  Rewrite this email, coming from {sender} to target this voter: {msg}.\"\n",
    "    input_text += 'Use an informal tone and do not mention the data in the profile in the email.'\n",
    "     \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model= model,\n",
    "        messages=[ {\"role\": \"user\", \"content\": input_text}\n",
    "        ]\n",
    "    )\n",
    "    text = response['choices'][0]['message']['content'].replace('\"','')\n",
    "    print(f\"Voter {profile_row}: {tr.fill(profile_str,width = 70)}\")\n",
    "    print(f\"Response:\\n{tr.fill(text,width = 75)}\\n\")\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
