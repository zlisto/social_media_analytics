{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKm1_AVTGoEO"
   },
   "source": [
    "# Homework 2\n",
    "This notebook provides some skeleton code to get you started on the homework. Add in your own code and markdown cells to answer the homework questions. If you want to submit the notebook as a PDF, make sure your code and markdowns are clear and concise to make grading easy for the TAs.\n",
    "\n",
    "This notebook can be opened in Colab \n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/zlisto/social_media_analytics/blob/main/HW2.ipynb)\n",
    "\n",
    "\n",
    "Before starting, select \"Runtime->Factory reset runtime\" to start with your directories and environment in the base state.\n",
    "\n",
    "If you want to save changes to the notebook, select \"File->Save a copy in Drive\" from the top menu in Colab. This will save the notebook in your Google Drive.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MsPnt5MbG5kt"
   },
   "source": [
    "# Clone GitHub Repository\n",
    "This will clone the repository to your machine. This includes the code and data files. Then change into the directory of the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XvGx5pxlG6_m"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/zlisto/social_media_analytics\n",
    "\n",
    "import os\n",
    "os.chdir(\"social_media_analytics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kh1PIX5LG-uf"
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A_l4DiveG_dk"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import umap\n",
    "import gensim.downloader as api\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "import sklearn.cluster as cluster\n",
    "from sklearn import metrics\n",
    "from scipy import stats\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "import scripts.TextAnalysis as ta\n",
    "from scripts.api import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ttgCTdwAGoET"
   },
   "source": [
    "# Problem 1. Cluster a User's Tweets (57 points)\n",
    "\n",
    "In this problem we are going to cluster the tweets of a single user.  Our goal is to determine different topics this person tweets about.  \n",
    "\n",
    "The user is social media influencer Kim Kardashian, with screen name is KimKardashian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2vGltquJGoET"
   },
   "source": [
    "#### 1. (12 points) Load tweets\n",
    "\n",
    "Load the tweets into a dataframe and call it `df`. The tweets are in the file `\"data/HW2.db\"` in the table `\"user_tweets\"`.  Remeber that you do not need to put the `.db` in the filename when loading the tweets.  Remove all columns except `\"screen_name\"` and `\"text\"`.   Then, use the `text_clean` function to clean the text and remove any clean tweets with length equal to zero.  Finally, select from `df` only the tweets where `\"screen_name\"` equals KimKardashian and call the dataframe `df_kim`.  Use the `.copy()` function to make `df_kim` a copy of the original dataframe so we can add columns to it later safely.\n",
    "\n",
    "How many tweets are in `df_kim` after this process?  Print out your answer.\n",
    "\n",
    "Print the head of the `df_kim`.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GazMjG4hGoEU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VKXMdz3ZGoEV"
   },
   "source": [
    "#### 2. (6 points) TF Embedding\n",
    "Calculate the term frequency embedding of the KimKardashian tweets.  \n",
    "\n",
    "How big is the vocabulary?  Print your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-F6iKgu0GoEW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ClzxeAGGoEX"
   },
   "source": [
    "#### 3. (12 points) Fit LDA Model\n",
    "\n",
    "Fit an LDA model to the KimKardashian tweets with 3 topics.  \n",
    "\n",
    "Make a pyLDAviz visualization of the topics.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jA8sI22dGoEX"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6VqvVORJ1JQ9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGmC8AKGGoEY"
   },
   "source": [
    "#### 4. (5 points) LDA Embedding\n",
    "\n",
    "Use the fit LDA model to convert the tf embedding into a topic vector embedding for the tweets.  \n",
    "\n",
    "What is the dimension of the embedding?  Print your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7jvwsCxxGoEZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YyonC-DzGoEZ"
   },
   "source": [
    "#### 5. (9 points) K-Means Clustering\n",
    "\n",
    "Calculate the k-means clusters of the LDA topic vectors using 3 clusters.  Add a column to the dataframe with the tweets called `\"kmeans_label_lda\"` that contains the k-means cluster labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hg-20JprGoEa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7npEA0t1GoEa"
   },
   "source": [
    "#### 6. (13 points) Cluster Wordclouds\n",
    "\n",
    "Plot the word cloud for each cluster (a `for` loop might be useful here).  Don't forget to remove stopwords.   Also add \"kimkardashian\" (all lowercase) to the stopwords set.  Since Kim's screen name is a common word in this corpus, we don't need to display it in the wordclouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1b9GKBYoGoEa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6snS3q2BGoEb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHj-7skZGoEb"
   },
   "source": [
    "#### 7. (0 points) Cluster Analysis\n",
    "\n",
    "If you are not familiar with American pop culture these word clouds may not make any sense to you.  But if you are, or are curious about Kim Kardashian's tweet topics, try to provide a unifying theme for each cluster based on the word clouds.  This question is for fun, so no worries if you want to skip it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UhmfhrOTGoEb"
   },
   "source": [
    "**your answer here**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U0fSiFKjGoEc"
   },
   "source": [
    "# Problem 2. Finding User Communities by Clustering Tweets (54 points)\n",
    "\n",
    "In this problem we are going to cluster the tweets from multiple Twitter users.  We are going to try and form communities of people from these tweet clusters.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RycbCU6lGoEc"
   },
   "source": [
    "#### 1. (8 points) Load tweets\n",
    "\n",
    "Load the tweets into a dataframe and call it `df`. The tweets are in the file `\"data/HW2.db\"` in the table `\"user_tweets\"`.  Remove all columns except `\"screen_name\"` and `\"text\"`.   Then, use the `text_clean` function to clean the text and remove any clean tweets with length equal to zero.  \n",
    "\n",
    "How many tweets in `df`?  Print your answer. \n",
    "\n",
    "Print a random sample of five tweets from `df`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yRYyCXfQGoEd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JTNt1lfLGoEd"
   },
   "source": [
    "#### 2. (6 points) TF-IDF Embedding\n",
    "\n",
    "Calculate the term frequency inverse document frequency (tf-idf) embedding of the tweets.  How big is the vocabulary?  Print your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UzdDQEvOGoEd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fx3kOwJsGoEe"
   },
   "source": [
    "#### 3. (6 points) UMAP Embedding\n",
    "Calculate the 2 dimensional UMAP embedding of the tf-idf embedding.  Then add two columns to `df` called `\"umap_tfidf_x\"` and `\"umap_tfidf_y\"` equal to the x and y coordinates of the UMAP embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tjhLkgLdGoEe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xiv_QpTtGoEe"
   },
   "source": [
    "#### 4. (8 points) K-Means Clustering\n",
    "\n",
    "Calculate the k-means clusters of the umap embedding using four clusters.  Add a column to the dataframe with the tweets called `\"kmeans_label_tfidf_umap\"` that contains the kmeans cluster labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TiDpD3yIGoEe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZarrMH1vGoEf"
   },
   "source": [
    "#### 5. (10 points) Scatterplots\n",
    "\n",
    "Make two scatter plots of the UMAP embedding: one where the `hue` is the screen name of the user, and the other where the `hue` is the k-means cluster label.  Be sure to include a legend and a title for each plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3_eV2EMnGoEf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "riyy-aZ6GoEf"
   },
   "source": [
    "#### 6. (14 points) Wordcloud and Screen Name Histogram\n",
    "\n",
    "Plot the word cloud and screen name histogram in each cluster using the `subplot` function (a `for` loop might be useful here).  Don't forget to remove stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TYwH7Vw_GoEf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i1ui4WfqGoEf",
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yb_vYOQZGoEg"
   },
   "source": [
    "#### 7. (2 points) Cluster Analyis\n",
    "\n",
    "You might notice that in each cluster certain users have many tweets while others have very few.  Look at the screen name histograms and try to identify two distinct communities of users.  Who are in these communities and what is their unifying theme?  It will be helpful to look up who these users are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_kawa9loyTW"
   },
   "source": [
    "**your answer here**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
